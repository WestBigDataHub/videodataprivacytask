{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is intended to be used as an introduction to <b>OpenCV</b> as well as other Python libraries that will help you navigate through this task. If you are unfamiliar with the task it is recommended to spend some time looking through our [github](https://github.com/WestBigDataHub/videoprivacytask) site to familiarize yourself before working through this notebook.\n",
    "\n",
    "Any links contained in this notebook are intended to help you understand more about the highlighted topic and it is recommended to take time to read about any topics you may not understand while working through the notebook.\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    "If you are interested in setting up a similar notebook environment locally you should follow the steps on our github site under the Tutorials section. This can be useful for downloading some of our notebooks as well as setting up a more interactive environment to work through your own implementation.\n",
    "\n",
    "### What is OpenCV\n",
    "\n",
    "OpenCV is a popular open-source computer vision library originally developed in C/C++ with a stable Python release being introduced in 2009. [Computer Vision](https://machinelearningmastery.com/what-is-computer-vision/) is simply a field that is concerned with developing techniques to help computers analyze and understand the content contained in an image or video through the use of algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "In any Python project we will first need to import relevant libraries that will be used. For the purpose of this example we are going to import three libraries: 1) cv2, 2) common, 3) numpy.\n",
    "\n",
    "1. <b>cv2</b> is simply the notation for importing the openCV library that was dicussed above\n",
    "2. <b>common</b> - contains a few useful openCV functions\n",
    "3. <b>numpy</b> - often abbreviated as np for simplicity, this is a Python library which adds support for large, multi-dimensional arrays and matrices as well as a collection of high-level mathematical functions to operate on these arrays. In computer vision images and video are simply collections of pixels which can be represented using arrays so this library is very useful to simplify operations on these structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import common\n",
    "import numpy as np\n",
    "\n",
    "# These imports are inteded to improve the notebook experience\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these imports we can now display a basic image using the openCV imread function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread('driver_face.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the output from this function is a multi-dimensional array encoding of pixel values contained in the image. We can use the below function to assign our image to a variable <b>img</b>. The image we are using in the example below comes directly from our [dataset](https://github.com/WestBigDataHub/videoprivacytask/tree/master/data) that we are using in this task.\n",
    "\n",
    "<b>NOTE</b> - When we display images in this notebook we use plt.imshow but when working outside a jupyter notebook using opencv.imshow will open a window containing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('driver_face.jpg')\n",
    "cv2.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the colors in the above image do not look quite right. This is because openCV doesn't store images in RGB format but rather BGR format. In order to convert to the standard RGB color space we can use the following code to split our image into its various channels and then we merge those chanels in the proper order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = cv2.split(img) #Split into various channels\n",
    "merged = cv2.merge([r, g, b]) #Merge in RGB order\n",
    "plt.imshow(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shorthand for doing this color conversion in openCV is shown below and is much easier to use once you understand the basic concept above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_merged = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(opencv_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will try to get an image from a video and use our [RetinaFace](https://github.com/serengil/retinaface) (provided in our data folder on github) detection coordinates in order to crop out the face contained in a single frame of that video. For this example we pick <b>frame 30</b> of the video which roughly corresponds to the image used above.\n",
    "\n",
    "First, we will load in the entire video and capture the image corresponding to the exact frame we need. We effectively use the VideoCapture function in order to read in the video and then we use the set function in the [VideoCapture](https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html) class to set the next frame to read. After we do this then we can call the read function to capture the proper image from that frame in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('T002_ActionsShorter_mini_3239_3347_Use-Radio-or-Gadget.mp4')\n",
    "total_frames = cap.get(7) # Gets the total frames from our video\n",
    "cap.set(1, 30) # Sets next frame to read \n",
    "ret, frame = cap.read() # Reads next frame\n",
    "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Convert frame to RGB\n",
    "plt.imshow(frame_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the desired frame we can use our RetinaFace coordinates to crop out the part of the frame containing the face. We are interested in the x, y, w, h values for each detection as these can be used to create a bounding box or capture a smaller part of the image. The detection coordiantes we have gathered are roughly the below values:<br><br>\n",
    "x = 174 <br>\n",
    "y = 65 <br>\n",
    "w = 137 <br>\n",
    "h = 194 <br>\n",
    "\n",
    "Notice that image slicing can be done using brackets and we can combine this with our above x, y, w, h values in the form <b>image[y:y+height, x:x+width]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = 174, 65, 137, 194\n",
    "cropped = frame_rgb[y:y+h, x:x+w]\n",
    "plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Loop\n",
    "\n",
    "Now that we have seen the above example we will look at a loop that reads in a single video and goes through each frame, capturing the corresponding face from each. This basic structure is something that you should use throughout the task for analyzing video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # This library can be useful for reading in the coordinates for RetinaFace csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas](https://pandas.pydata.org/) is a Python library for data manipulation and analysis that offers data structures and operations for manipulating numberical tables and time series. This library may be useful outside of analyzing the RetinaFace detection coordinates but currently we are using it for analyzing the csv file containing our RetinaFace detection coordinates.\n",
    "\n",
    "The code below reads in our csv file containing the detection coordinates and displays the first 5 rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections = pd.read_csv('T002_ActionsShorter_mini_3239_3347_Use-Radio-or-Gadget.csv')\n",
    "face_detections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each row corresponds to a separate frame in the video. We are interested in gathering the x, y, w, h column values for each frame so that we are able to use that when analyzing the video. Here is how we can get these values for quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = face_detections[['x', 'y', 'w', 'h']].round(0).astype(int)\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic structure of a loop in opencv that iterates through the video and captures the face at each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections = pd.read_csv('T002_ActionsShorter_mini_3239_3347_Use-Radio-or-Gadget.csv')\n",
    "coordinates = face_detections[['x', 'y', 'w', 'h']]\n",
    "coordinates = coordinates.round(0).astype(int) # Rounds the detection coordinates and converts to integers\n",
    "\n",
    "cap = cv2.VideoCapture('T002_ActionsShorter_mini_3239_3347_Use-Radio-or-Gadget.mp4')\n",
    "success, img = cap.read()\n",
    "frame_number = 0\n",
    "while success:\n",
    "    x, y, w, h = coordinates.iloc[0] # Gets the coordinates and assign values to x, y, w, h\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    # Do something with the face image\n",
    "    success, img = cap.read() # Iterate to next frame\n",
    "    frame_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Materials\n",
    "\n",
    "If you found this tutorial helpful and want to learn more about openCV usage [this](https://medium.com/analytics-vidhya/introduction-to-opencv-cc771730577a) link will be helpful. It contains a collection of 4 notebooks (the material in the first one has been covered here) that are useful in learning the basics of image processing, features in computer vision and cascade classification. \n",
    "\n",
    "If you are interested in some more openCV tutorials these can be found [here](https://docs.opencv.org/4.5.2/d6/d00/tutorial_py_root.html). These tutorials have a broader range in topics and can be a good reference when learning what openCV can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
